{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyspark Handling Missing Values\n",
    "\n",
    "    Dropping Columns\n",
    "    Dropping Rows\n",
    "    Various Parameter in Dropping functionalities\n",
    "    Handling Missing values by Mean, Median and Mode - Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark =  spark.read.csv('Book2.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|  Vekash|  22|        10| 30000|\n",
      "|   Krish|  31|         8| 24000|\n",
      "|Sudhansh|  30|         4| 35000|\n",
      "|   Sunny|  29|         3| 15000|\n",
      "|    paul|  24|         1| 16000|\n",
      "|  Harsha|  21|         2| 20000|\n",
      "| Shubham|  23|         2| 28000|\n",
      "|  Mahesh|NULL|      NULL| 24000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  22|        10| 30000|\n",
      "|  31|         8| 24000|\n",
      "|  30|         4| 35000|\n",
      "|  29|         3| 15000|\n",
      "|  24|         1| 16000|\n",
      "|  21|         2| 20000|\n",
      "|  23|         2| 28000|\n",
      "|NULL|      NULL| 24000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### drop the columns\n",
    "\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|  Vekash| 22|        10| 30000|\n",
      "|   Krish| 31|         8| 24000|\n",
      "|Sudhansh| 30|         4| 35000|\n",
      "|   Sunny| 29|         3| 15000|\n",
      "|    paul| 24|         1| 16000|\n",
      "|  Harsha| 21|         2| 20000|\n",
      "| Shubham| 23|         2| 28000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|  Vekash| 22|        10| 30000|\n",
      "|   Krish| 31|         8| 24000|\n",
      "|Sudhansh| 30|         4| 35000|\n",
      "|   Sunny| 29|         3| 15000|\n",
      "|    paul| 24|         1| 16000|\n",
      "|  Harsha| 21|         2| 20000|\n",
      "| Shubham| 23|         2| 28000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### any, all\n",
    "\n",
    "df_pyspark.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|  Vekash|  22|        10| 30000|\n",
      "|   Krish|  31|         8| 24000|\n",
      "|Sudhansh|  30|         4| 35000|\n",
      "|   Sunny|  29|         3| 15000|\n",
      "|    paul|  24|         1| 16000|\n",
      "|  Harsha|  21|         2| 20000|\n",
      "| Shubham|  23|         2| 28000|\n",
      "|  Mahesh|NULL|      NULL| 24000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|  Vekash| 22|        10| 30000|\n",
      "|   Krish| 31|         8| 24000|\n",
      "|Sudhansh| 30|         4| 35000|\n",
      "|   Sunny| 29|         3| 15000|\n",
      "|    paul| 24|         1| 16000|\n",
      "|  Harsha| 21|         2| 20000|\n",
      "| Shubham| 23|         2| 28000|\n",
      "|    NULL| 34|        10| 38000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold\n",
    "\n",
    "df_pyspark.na.drop(how=\"any\",thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "|  Vekash| 22|        10| 30000|\n",
      "|   Krish| 31|         8| 24000|\n",
      "|Sudhansh| 30|         4| 35000|\n",
      "|   Sunny| 29|         3| 15000|\n",
      "|    paul| 24|         1| 16000|\n",
      "|  Harsha| 21|         2| 20000|\n",
      "| Shubham| 23|         2| 28000|\n",
      "|    NULL| 34|        10| 38000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"any\",subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          Name| age|Experience|Salary|\n",
      "+--------------+----+----------+------+\n",
      "|        Vekash|  22|        10| 30000|\n",
      "|         Krish|  31|         8| 24000|\n",
      "|      Sudhansh|  30|         4| 35000|\n",
      "|         Sunny|  29|         3| 15000|\n",
      "|          paul|  24|         1| 16000|\n",
      "|        Harsha|  21|         2| 20000|\n",
      "|       Shubham|  23|         2| 28000|\n",
      "|        Mahesh|NULL|      NULL| 24000|\n",
      "|Missing Values|  34|        10| 38000|\n",
      "|Missing Values|  36|      NULL|  NULL|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## filling the Missing Value\n",
    "df_pyspark.na.fill('Missing Values').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+----------+------+\n",
      "|          Name|age|Experience|Salary|\n",
      "+--------------+---+----------+------+\n",
      "|        Vekash| 22|        10| 30000|\n",
      "|         Krish| 31|         8| 24000|\n",
      "|      Sudhansh| 30|         4| 35000|\n",
      "|         Sunny| 29|         3| 15000|\n",
      "|          paul| 24|         1| 16000|\n",
      "|        Harsha| 21|         2| 20000|\n",
      "|       Shubham| 23|         2| 28000|\n",
      "|        Mahesh|  0|         0| 24000|\n",
      "|Missing Values| 34|        10| 38000|\n",
      "|Missing Values| 36|         0|     0|\n",
      "+--------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace NULL in string and numeric columns separately\n",
    "df_pyspark.na.fill({\"Name\": \"Missing Values\", \"age\": 0, \"Experience\": 0, \"Salary\": 0}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|  Vekash|  22|        10| 30000|\n",
      "|   Krish|  31|         8| 24000|\n",
      "|Sudhansh|  30|         4| 35000|\n",
      "|   Sunny|  29|         3| 15000|\n",
      "|    paul|  24|         1| 16000|\n",
      "|  Harsha|  21|         2| 20000|\n",
      "| Shubham|  23|         2| 28000|\n",
      "|  Mahesh|NULL|      NULL| 24000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "|    NULL|  36|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age','Experience','Salary'],\n",
    "    outputCols=[\"{}_imputed\".fo rmat(c) for c in ['age', 'Experience', 'Salary']]\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "# imputer = Imputer(inputCols='',outputCols='').setStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Vekash|  22|        10| 30000|         22|                10|         30000|\n",
      "|   Krish|  31|         8| 24000|         31|                 8|         24000|\n",
      "|Sudhansh|  30|         4| 35000|         30|                 4|         35000|\n",
      "|   Sunny|  29|         3| 15000|         29|                 3|         15000|\n",
      "|    paul|  24|         1| 16000|         24|                 1|         16000|\n",
      "|  Harsha|  21|         2| 20000|         21|                 2|         20000|\n",
      "| Shubham|  23|         2| 28000|         23|                 2|         28000|\n",
      "|  Mahesh|NULL|      NULL| 24000|         27|                 5|         24000|\n",
      "|    NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|    NULL|  36|      NULL|  NULL|         36|                 5|         25555|\n",
      "+--------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add imputation cols to df\n",
    "\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
